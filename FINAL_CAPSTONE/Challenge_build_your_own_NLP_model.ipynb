{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import spacy\n",
    "from nltk.corpus import stopwords, gutenberg\n",
    "import spacy\n",
    "from spacy.pipeline import SentenceSegmenter\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = spacy.load('en')\n",
    "#import nltk \n",
    "#from nltk.corpus import stopwords set(stopwords.words('english'))\n",
    "\n",
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n",
    "from spacy.pipeline import SentenceSegmenter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer, normalize\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "# Evaluate the performance of the clusters\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import scikitplot.plotters as skplt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alice= strip_headers(load_etext(19002)).strip()\n",
    "Christmas= strip_headers(load_etext(19337)).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#round 1 of cleaning data\n",
    "def text_cleaner_1(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--', ' ',text)\n",
    "    #remove brackets\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", '', text)\n",
    "    #remove volume\n",
    "    text = re.sub(r'VOLUME \\w', '', text)\n",
    "    #remove words contaning numbers\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    #remove punctuation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # Search for all non-letters\n",
    "    # Replace all non-letters with spaces\n",
    "    # Remove story section separators, add uniform story section separator\n",
    "    text = re.sub('(\\s*\\*){5}', '@SentBoundary@' , text)\n",
    "    text = re.sub(r'C[Hh][Aa][Pp][Tt][Ee][Rr] [\\d\\w]+', '@SentBoundary@' , text)\n",
    "    #text = re.sub(\"[^a-zA-Z]\", \" \", str(text))\n",
    "    #remove white space\n",
    "    tex= text.lower()\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alice=text_cleaner_1(Alice)[:100000]\n",
    "Christmas=text_cleaner_1(Christmas)[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Christmas_doc = nlp(Christmas)\n",
    "Alice_doc = nlp(Alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alice_sents = [[sent, 'Alice'] for sent in Alice_doc.sents]\n",
    "Christmas_sents = [[sent, 'Christmas'] for sent in Christmas_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(Online, Distributed, Proofreading, Team, at, ...</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(UNDER, GROUND, BEING, A, FACSIMILE, OF, THE, ...</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(BY, LEWIS, CARROLL)</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(WITH, THIRTYSEVEN, ILLUSTRATIONS, BY, THE, AU...</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(I, DOWN, THE, RABBITHOLE)</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0      1\n",
       "0  (Online, Distributed, Proofreading, Team, at, ...  Alice\n",
       "1  (UNDER, GROUND, BEING, A, FACSIMILE, OF, THE, ...  Alice\n",
       "2                               (BY, LEWIS, CARROLL)  Alice\n",
       "3  (WITH, THIRTYSEVEN, ILLUSTRATIONS, BY, THE, AU...  Alice\n",
       "4                         (I, DOWN, THE, RABBITHOLE)  Alice"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = pd.DataFrame(Alice_sents + Christmas_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(Alice_doc)\n",
    "christmaswords = bag_of_words(Christmas_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + christmaswords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n",
      "Processing row 450\n",
      "Processing row 500\n",
      "Processing row 550\n",
      "Processing row 600\n",
      "Processing row 650\n",
      "Processing row 700\n",
      "Processing row 750\n",
      "Processing row 800\n",
      "Processing row 850\n",
      "Processing row 900\n",
      "Processing row 950\n",
      "Processing row 1000\n",
      "Processing row 1050\n",
      "Processing row 1100\n",
      "Processing row 1150\n",
      "Processing row 1200\n",
      "Processing row 1250\n",
      "Processing row 1300\n",
      "Processing row 1350\n",
      "Processing row 1400\n",
      "Processing row 1450\n",
      "Processing row 1500\n",
      "Processing row 1550\n",
      "Processing row 1600\n",
      "Processing row 1650\n",
      "Processing row 1700\n",
      "Processing row 1750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fragment</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>ALICE</th>\n",
       "      <th>excuse</th>\n",
       "      <th>slate</th>\n",
       "      <th>chamber</th>\n",
       "      <th>pudding</th>\n",
       "      <th>ruddy</th>\n",
       "      <th>cling</th>\n",
       "      <th>convey</th>\n",
       "      <th>...</th>\n",
       "      <th>peg</th>\n",
       "      <th>Bobs</th>\n",
       "      <th>appalling</th>\n",
       "      <th>Future</th>\n",
       "      <th>Public</th>\n",
       "      <th>attach</th>\n",
       "      <th>key</th>\n",
       "      <th>snugly</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Online, Distributed, Proofreading, Team, at, ...</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(UNDER, GROUND, BEING, A, FACSIMILE, OF, THE, ...</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(BY, LEWIS, CARROLL)</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(WITH, THIRTYSEVEN, ILLUSTRATIONS, BY, THE, AU...</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, DOWN, THE, RABBITHOLE)</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3054 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fragment curiosity ALICE excuse slate chamber pudding ruddy cling convey  \\\n",
       "0        0         0     0      0     0       0       0     0     0      0   \n",
       "1        0         0     0      0     0       0       0     0     0      0   \n",
       "2        0         0     0      0     0       0       0     0     0      0   \n",
       "3        0         0     0      0     0       0       0     0     0      0   \n",
       "4        0         0     0      0     0       0       0     0     0      0   \n",
       "\n",
       "   ... peg Bobs appalling Future Public attach key snugly  \\\n",
       "0  ...   0    0         0      0      0      0   0      0   \n",
       "1  ...   0    0         0      0      0      0   0      0   \n",
       "2  ...   0    0         0      0      0      0   0      0   \n",
       "3  ...   0    0         0      0      0      0   0      0   \n",
       "4  ...   0    0         0      0      0      0   0      0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Online, Distributed, Proofreading, Team, at, ...       Alice  \n",
       "1  (UNDER, GROUND, BEING, A, FACSIMILE, OF, THE, ...       Alice  \n",
       "2                               (BY, LEWIS, CARROLL)       Alice  \n",
       "3  (WITH, THIRTYSEVEN, ILLUSTRATIONS, BY, THE, AU...       Alice  \n",
       "4                         (I, DOWN, THE, RABBITHOLE)       Alice  \n",
       "\n",
       "[5 rows x 3054 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9763257575757576\n",
      "\n",
      "Test set score: 0.7531914893617021\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1056, 3052) (1056,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9630681818181818\n",
      "\n",
      "Test set score: 0.7900709219858156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2') # No need to specify l2 as it's the default. But we put it for demonstration.\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_sents = [' '.join([token.lemma_ for token in sent]) for sent in sentences[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "punc = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}',\"%\", 'pron']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(punc)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(lemma_sents, \n",
    "                                                    sentences[1], \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=0)\n",
    "\n",
    "#creating our Tf_idf vectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer(max_df= 0.80, # drop words that occur in more than this % of paragraphs\n",
    "                             min_df=5, # only use words that appear at least 10 times\n",
    "                             stop_words=stop_words, \n",
    "                             lowercase=True, #convert everything to lower case\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "# Fit and transform training data set, only transform test\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with CV and tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70676692 0.7518797  0.7443609  0.78787879 0.78787879 0.72727273\n",
      " 0.71212121 0.7480916  0.74045802 0.73282443]\n",
      "0.7439533079750035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr = LogisticRegression(penalty='l1')\n",
    "\n",
    "scores = cross_val_score(lr, X_train_tfidf, y_train, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with CV and tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68421053 0.72180451 0.7518797  0.8030303  0.76515152 0.79545455\n",
      " 0.71969697 0.77099237 0.76335878 0.75572519]\n",
      "0.7531304406053302\n",
      "RF is better than LR\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rfc, X_train_tfidf, y_train, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "print('RF is better than LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8484848484848485\n",
      "\n",
      "Test set score: 0.7913832199546486\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=1000, max_depth=7, min_samples_split= 10, max_features=5)\n",
    "\n",
    "train = rfc.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train_tfidf, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 329 (0.0685) scrooge\n",
      "2. feature 8 (0.0582) alice\n",
      "3. feature 145 (0.0265) ghost\n",
      "4. feature 63 (0.0251) christmas\n",
      "5. feature 368 (0.0165) spirit\n",
      "6. feature 298 (0.0164) queen\n",
      "7. feature 396 (0.0154) think\n",
      "8. feature 229 (0.0153) man\n",
      "9. feature 249 (0.0151) mouse\n",
      "10. feature 158 (0.0140) gryphon\n",
      "11. feature 303 (0.0133) rabbit\n",
      "12. feature 412 (0.0132) turtle\n",
      "13. feature 264 (0.0119) oh\n",
      "14. feature 219 (0.0116) little\n",
      "15. feature 410 (0.0115) try\n",
      "16. feature 232 (0.0100) marley\n",
      "17. feature 162 (0.0089) hand\n",
      "18. feature 53 (0.0088) caterpillar\n",
      "19. feature 252 (0.0086) mrs\n",
      "20. feature 27 (0.0083) begin\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "terms = vectorizer_tfidf.get_feature_names()\n",
    "\n",
    "for f in range(20):\n",
    "    print('{}. feature {} ({:.4f}) {}'.format((f+1), indices[f], importances[indices[f]], terms[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(0,20), importances[indices][:20], color=\"r\", align=\"center\")\n",
    "plt.xticks(range(20), indices, rotation=90)\n",
    "plt.xlim([-1, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
