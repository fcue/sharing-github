{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This section is where I upload all of my tweets, clean and turn them into tsv files for BERT classifying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "prefix = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my train data\n",
    "df=pd.read_csv('all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new= pd.DataFrame(df[['text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I know there's nan's in label section since I intentionally left it blank to try to achieve a more balance class\n",
    "#while manually labeling the data\n",
    "new.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1850\n",
       "1.0     348\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOT FINAL DATA. HAVE MORE DATA TO PROCESS AND UPLOAD HERE\n",
    "new.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>RT @HockeyinVegas: The @GoldenKnights'  Marc-A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>Pneumonia is dangerous guys it’s not the flu ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a</td>\n",
       "      <td>I've lost 10 pounds in less than a week due to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>RT @greatestjubilee: there was actually a whol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>RT @hitchcockherd: You can find a family in ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label alpha                                               text\n",
       "0   0    0.0     a  RT @HockeyinVegas: The @GoldenKnights'  Marc-A...\n",
       "1   1    0.0     a  Pneumonia is dangerous guys it’s not the flu ,...\n",
       "2   2    1.0     a  I've lost 10 pounds in less than a week due to...\n",
       "3   3    0.0     a  RT @greatestjubilee: there was actually a whol...\n",
       "4   4    0.0     a  RT @hitchcockherd: You can find a family in ne..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting files that BERT understand. It requires an ID, label, alpha and text columns. \n",
    "train_df = pd.DataFrame({\n",
    "    'id':range(len(new)),\n",
    "    'label':new.iloc[:,-1],\n",
    "    'alpha':['a']*new.shape[0],\n",
    "    'text': new.iloc[:,-2].replace(r'\\n', ' ', regex=True)\n",
    "})\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('my_test_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.DataFrame(df1[['text', 'label']])\n",
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>RT @NWOMXNDX: Niggas posting chicken sandwiche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>RT @sallyKP: ALL THREE SIBLINGS HAD THE FLU VA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>RT @wirralct: #MyFluFact Flu... it's serious! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>Going from the flu to racing NoHo. WHAT COULD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>PLEASE SHARE  UV Light 185nm-254nm Safe for Hu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label alpha                                               text\n",
       "0   0    0.0     a  RT @NWOMXNDX: Niggas posting chicken sandwiche...\n",
       "1   1    0.0     a  RT @sallyKP: ALL THREE SIBLINGS HAD THE FLU VA...\n",
       "2   2    0.0     a  RT @wirralct: #MyFluFact Flu... it's serious! ...\n",
       "3   3    0.0     a  Going from the flu to racing NoHo. WHAT COULD ...\n",
       "4   4    0.0     a  PLEASE SHARE  UV Light 185nm-254nm Safe for Hu..."
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df = pd.DataFrame({\n",
    "    'id':range(len(df1)),\n",
    "    'label':df1.iloc[:,-1],\n",
    "    'alpha':['a']*df1.shape[0],\n",
    "    'text': df1.iloc[:,-2].replace(r'\\n', ' ', regex=True)\n",
    "})\n",
    "\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.tsv', sep='\\t', index=False, header=False)\n",
    "dev_df.to_csv('dev.tsv', sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our text cleaner\n",
    "#removing URLs and string beginning with @ \n",
    "def clean_tweets(text):\n",
    "    text= re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "    text=re.sub(r'http\\S+', '', text)\n",
    "    text= re.sub(r'RT @[\\w_]+:', '', text)\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    text= re.sub(r'\\b\\w{1,2}\\b', '', text)\n",
    "    text = re.split('\\W+', text)\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    text= \" \".join([word for word in text if not word.isdigit()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>RT @HockeyinVegas: The @GoldenKnights'  Marc-A...</td>\n",
       "      <td>The MarcAndre Fleury wa full participant prac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>Pneumonia is dangerous guys it’s not the flu ,...</td>\n",
       "      <td>Pneumonia dangerous guy not the flu look after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a</td>\n",
       "      <td>I've lost 10 pounds in less than a week due to...</td>\n",
       "      <td>Ive lost pound le than week due the amount tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>RT @greatestjubilee: there was actually a whol...</td>\n",
       "      <td>there wa actually whole compilation way felt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>RT @hitchcockherd: You can find a family in ne...</td>\n",
       "      <td>You can find family need whether it baby adop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13536</td>\n",
       "      <td>2193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>https://t.co/C1EngIvYkM</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13537</td>\n",
       "      <td>2194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a</td>\n",
       "      <td>Somehow within only being home for  3 days I’v...</td>\n",
       "      <td>Somehow within only being home for day come do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13538</td>\n",
       "      <td>2195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>RT @martingeddes: \"And that’s a problem for ma...</td>\n",
       "      <td>And that problem for many people They would r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13539</td>\n",
       "      <td>2196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>RT @Juchtervbergen: #ai #android #app #flu #ge...</td>\n",
       "      <td>android app flu gear Weather Channel app us W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13540</td>\n",
       "      <td>2197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>It only took me a week of the flu to put me ba...</td>\n",
       "      <td>only took week the flu put back bullshit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2198 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  label alpha                                               text  \\\n",
       "0         0    0.0     a  RT @HockeyinVegas: The @GoldenKnights'  Marc-A...   \n",
       "1         1    0.0     a  Pneumonia is dangerous guys it’s not the flu ,...   \n",
       "2         2    1.0     a  I've lost 10 pounds in less than a week due to...   \n",
       "3         3    0.0     a  RT @greatestjubilee: there was actually a whol...   \n",
       "4         4    0.0     a  RT @hitchcockherd: You can find a family in ne...   \n",
       "...     ...    ...   ...                                                ...   \n",
       "13536  2193    0.0     a                            https://t.co/C1EngIvYkM   \n",
       "13537  2194    1.0     a  Somehow within only being home for  3 days I’v...   \n",
       "13538  2195    0.0     a  RT @martingeddes: \"And that’s a problem for ma...   \n",
       "13539  2196    0.0     a  RT @Juchtervbergen: #ai #android #app #flu #ge...   \n",
       "13540  2197    0.0     a  It only took me a week of the flu to put me ba...   \n",
       "\n",
       "                                                   clean  \n",
       "0       The MarcAndre Fleury wa full participant prac...  \n",
       "1      Pneumonia dangerous guy not the flu look after...  \n",
       "2      Ive lost pound le than week due the amount tim...  \n",
       "3       there wa actually whole compilation way felt ...  \n",
       "4       You can find family need whether it baby adop...  \n",
       "...                                                  ...  \n",
       "13536                                                     \n",
       "13537  Somehow within only being home for day come do...  \n",
       "13538   And that problem for many people They would r...  \n",
       "13539   android app flu gear Weather Channel app us W...  \n",
       "13540          only took week the flu put back bullshit   \n",
       "\n",
       "[2198 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['clean']= train_df['text'].apply(lambda x: clean_tweets(x))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unclean text then renaming the clean column 'text'\n",
    "train_df.drop('text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns= {\"clean\": \"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now doing the same for test file\n",
    "dev_df['clean']= dev_df['text'].apply(lambda x: clean_tweets(x))\n",
    "dev_df.drop('text', axis=1, inplace=True)\n",
    "dev_df.rename(columns= {\"clean\": \"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving our files TSV files\n",
    "train_df.to_csv('data/train.tsv', sep='\\t', index=False, header=False)\n",
    "dev_df.to_csv('data/dev.tsv', sep='\\t', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
